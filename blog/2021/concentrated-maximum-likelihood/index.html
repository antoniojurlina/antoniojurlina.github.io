<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Antonio  Jurlina | Concentrated Maximum Likelihood</title>
<meta name="description" content="Blog for miscellaneous writing and projects not written in Python/R/SQL. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.xyz/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚙️</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/blog/2021/concentrated-maximum-likelihood/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Antonio</span>   Jurlina
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Portfolio -->
          <li class="nav-item ">
            <a class="nav-link" href="https://antoniojurlina.github.io/portfolio/">portfolio
            </a>
          </li>
          <!-- Blog -->
          <li class="nav-item active">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/archive/">
                archive
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/resume/">
                resume
                
              </a>
          </li>
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Concentrated Maximum Likelihood</h1>
    <p class="post-meta">June 25, 2021</p>
  </header>

  <article class="post-content">
    <p><br /></p>

<p>Usually, the maximum likelihood (ML) estimator for the population parameters \(\beta\) and \(\sigma^2\),  in the classical linear regression model(\(Y_i = X_i\beta + \varepsilon_i\)), are derived directly. Alternatively, the ML estimators can be obtained by first “concentrating” the log-likelihood function with respect to one of the parameters. For example, concentrating the function with respect to \(\sigma^2\) – this is a convenient approach for problems that contain variance terms. This means differentiating the log-likelihood function with respect to \(\sigma^2\), solving the resulting first-order condition for \(\sigma^2\) as a function of the data and the remaining parameters, and then substituting the result back into the original log-likelihood function. This yields the concentrated log-likelihood function. The ML estimator for \(\beta\) can then be found my maximizing the concentrated log-likelihood function with respect to \(\beta\). Here, I will demonstrate this process.</p>

<p><br /></p>

<ul>
  <li>Deriving the ML estimator for \(\sigma^2\) as a function of the data and the remaining parameters.</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>The probability density function<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>  for the classical linear regression model,</td>
    </tr>
    <tr>
      <td>assuming \(Y_i \sim N(X_i\beta, \sigma^2)\), is:</td>
    </tr>
  </tbody>
</table>

\[f(Y_i|X_i,\theta)=\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}\frac{(Y_i-X_i\beta)^2}{\sigma^2}}\]

<table>
  <tbody>
    <tr>
      <td>From there I proceed to set up the (log) likelihood equation:</td>
    </tr>
  </tbody>
</table>

\[L(\theta|Y_N,X)=\prod_{i=1}^{N}f(Y_i|X_i,\theta)\]

\[ln[L(\theta|Y_N,X)]=\sum_{i=1}^Nln\left[f(Y_i|X_i,\theta)\right]\]

\[LL(\theta|Y_N,X)=\sum_{i=1}^Nln\left[\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}\frac{(Y_i-X_i\beta)^2}{\sigma^2}}\right]\]

\[LL(\theta|Y_N,X)=\sum_{i=1}^Nln\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)+\sum_{i=1}^Nln\left(e^{-\frac{1}{2}\frac{(Y_i-X_i\beta)^2}{\sigma^2}}\right)\]

\[LL(\theta|Y_N,X)=Nln\left(\frac{1}{\sqrt{2\pi\sigma^2}}\right)-\frac{1}{2}\frac{\sum_{i=1}^N(Y_i-X_i\beta)^2}{\sigma^2}\]

\[LL(\theta|Y_N,X)=Nln(1)-Nln\left(\sqrt{2\pi\sigma^2}\right)-\frac{1}{2\sigma^2}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left(\sigma^2\right)-\frac{1}{2\sigma^2}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

<table>
  <tbody>
    <tr>
      <td>Now, I take a derivative of the log-likelihood function with respect to \(\sigma^2\):</td>
    </tr>
  </tbody>
</table>

\[\frac{\partial LL}{\partial \sigma^2}=-\frac{N}{2}\frac{1}{\sigma^2}+\frac{1}{2\sigma^2\sigma^2}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

<table>
  <tbody>
    <tr>
      <td>Finally, setting the derivative to zero and solving for \(\sigma^2\):</td>
    </tr>
  </tbody>
</table>

\[-\frac{N}{2}\frac{1}{\sigma^2}+\frac{1}{2\sigma^2\sigma^2}\sum_{i=1}^N(Y_i-X_i\beta)^2=0\]

\[\frac{-\sigma^2N+\sum_{i=1}^N(Y_i-X_i\beta)^2}{2\sigma^2\sigma^2}=0\]

\[-\sigma^2N=-\sum_{i=1}^N(Y_i-X_i\beta)^2\]

\[\sigma^2=\frac{1}{N}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

<p><br /></p>

<ul>
  <li>Using the result from previous part, I will derive the concentrated log-likelihood function.</li>
</ul>

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left(\sigma^2\right)-\frac{1}{2\sigma^2}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

<table>
  <tbody>
    <tr>
      <td>Substituting in the result for \(\sigma^2\):</td>
    </tr>
  </tbody>
</table>

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left(\frac{1}{N}\sum_{i=1}^N(Y_i-X_i\beta)^2\right)-\frac{1}{\frac{2}{N}\sum_{i=1}^N(Y_i-X_i\beta)^2}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left(\frac{1}{N}\sum_{i=1}^N(Y_i-X_i\beta)^2\right)-\frac{N}{2}\]

<table>
  <tbody>
    <tr>
      <td>Switching to matrix form:</td>
    </tr>
  </tbody>
</table>

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left[\frac{1}{N}(Y_N-X\beta)^T(Y_N-X\beta)\right]-\frac{N}{2}\]

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left[\frac{1}{N}\left(Y_N^TY_N-2\beta^TX^TY_N+\beta^TX^TX\beta\right)\right]-\frac{N}{2}\]

<p><br /></p>

<ul>
  <li>Using the concentrated log-likelihood I derive the ML estimator for \(\beta\).</li>
</ul>

<table>
  <tbody>
    <tr>
      <td>First, I take a derivative of the log-likelihood function with respect to \(\beta\):</td>
    </tr>
  </tbody>
</table>

\[\frac{\partial LL}{\partial \beta}=-\frac{N}{2}\frac{\frac{1}{N}\left(2X^TY_N+2X^TX\beta\right)}{\frac{1}{N}\left(Y_N^TY_N-2\beta^TX^TY_N+\beta^TX^TX\beta\right)}\]

\[\frac{\partial LL}{\partial \beta}=\frac{-N\left(X^TY_N+X^TX\beta\right)}{Y_N^TY_N-2\beta^TX^TY_N+\beta^TX^TX\beta}\]

<table>
  <tbody>
    <tr>
      <td>Then, I set the derivative to zero and solve for \(\beta\).</td>
    </tr>
  </tbody>
</table>

\[\frac{-N\left(X^TY_N+X^TX\beta\right)}{Y_N^TY_N-2\beta^TX^TY_N+\beta^TX^TX\beta}=0\]

\[X^TY_N+X^TX\beta\ = 0\]

\[X^TX\beta=X^TY_N\]

\[\widehat{\beta}_{MLE}=(X^TX)^{-1}X^TY_N\]

<p><br /></p>

<ul>
  <li>Using \(\widehat{\beta}\) to adjust the ML estimator for \(\sigma^2\) (from part a)).</li>
</ul>

\[\sigma^2=\frac{1}{N}\sum_{i=1}^N(Y_i-X_i\beta)^2\]

\[\sigma^2=\frac{1}{N}\left(Y_N-X\beta\right)^T\left(Y_N-X\beta\right)\]

\[\sigma^2=\frac{1}{N}\left(Y_N^TY_N-2\beta^TX^TY_N+\beta^TX^TX\beta\right)\]

<table>
  <tbody>
    <tr>
      <td>Substituting in the answer for \(\beta\):</td>
    </tr>
  </tbody>
</table>

\[\sigma^2=\frac{1}{N}\left[Y_N^TY_N-2\left((X^TX)^{-1}X^TY_N\right)^TX^TY_N+\left((X^TX)^{-1}X^TY_N\right)^TX^TX\left((X^TX)^{-1}X^TY_N\right)\right]\]

\[\sigma^2=\frac{1}{N}\left[Y_N^TY_N-2Y_N^TX\left((X^TX)^{-1}\right)^TX^TY_N+Y_N^TX\left((X^TX)^{-1}\right)^TX^TY_N\right]\]

\[\sigma^2=\frac{1}{N}\left[Y_N^TY_N-Y_N^TX\left((X^TX)^{-1}\right)^TX^TY_N\right]\]

<table>
  <tbody>
    <tr>
      <td>Considering that \(\left(A^{-1}\right)^T = \left(A^T\right)^{-1}\),</td>
    </tr>
  </tbody>
</table>

\[\widehat{\sigma^2}_{MLE}=\frac{1}{N}\left[Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N\right]\]

<p><br /></p>

<ul>
  <li>Now, I demonstrate that the order did not matter. That is, I show that the ML estimators of \(\sigma^2\) and \(\beta\) can be obtained by first concentrating with respect to \(\beta\) and then maximizing the concentrated log-likelihood thereby obtained, with respect to \(\sigma^2\).</li>
</ul>

\[\widehat{\beta}_{MLE}=(X^TX)^{-1}X^TY_N\]

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left(\sigma^2\right)-\frac{1}{2\sigma^2}\left(Y_N-X\beta\right)^T\left(Y_N-X\beta\right)\]

\[LL(\theta|Y_N,X)=-\frac{N}{2}ln(2\pi)-\frac{N}{2}ln\left(\sigma^2\right)-\frac{1}{2\sigma^2}\left[Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N\right]\]

\[\frac{\partial LL}{\partial \sigma^2}=-\frac{N}{2\sigma^2}+\frac{Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N}{2\sigma^2\sigma^2}\]

\[-\frac{N}{2\sigma^2}+\frac{Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N}{2\sigma^2\sigma^2}=0\]

\[\frac{Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N-\sigma^2N}{2\sigma^2\sigma^2}=0\]

\[Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N=\sigma^2N\]

\[\widehat{\sigma^2}_{MLE}=\frac{1}{N}\left[Y_N^TY_N-Y_N^TX(X^TX)^{-1}X^TY_N\right]\]

<p><br /> 
<br /></p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>the general form: \(f(x)=\frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{1}{2}\frac{(x-\mu)^2}{\sigma^2}}\) <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </article>

  

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Antonio  Jurlina.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>.

    
    
    Last updated: August 12, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
